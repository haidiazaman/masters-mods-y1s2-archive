{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we explore the use of autoencoders for image compression and denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "sns.set(font_scale=1.5, style='dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pokemon Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far our applications in this class have been rather serious. Here, to demonstrate the use of autoencoders we will use a fun dataset. The pokemon dataset!\n",
    "\n",
    "See [here](https://www.kaggle.com/vishalsubbiah/pokemon-images-and-types) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "kaggle.api.dataset_download_files(\n",
    "    'vishalsubbiah/pokemon-images-and-types',\n",
    "    path='./pokemon',\n",
    "    quiet=False,\n",
    "    unzip=True,\n",
    "    force=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are in multiple formats including png and jpg formats. So we will do some pre-processing and change all of them into (120, 120, 3) arrays, representing a RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "images = []\n",
    "\n",
    "fill_color = (255, 255, 255)\n",
    "\n",
    "for img in os.listdir('./pokemon/images/images'):\n",
    "    im = Image.open('./pokemon/images/images/{}'.format(img))\n",
    "    names.append(img.split('.')[0])\n",
    "    if img.split('.')[1] == 'png':\n",
    "        im = im.convert(\"RGBA\")\n",
    "        if im.mode in ('RGBA', 'LA'):\n",
    "            bg = Image.new(im.mode[:-1], im.size, fill_color)\n",
    "            bg.paste(im, im.split()[-1])\n",
    "            im = bg\n",
    "    images.append(np.asarray(im))\n",
    "images = np.asarray(images) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a function to plot the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, n_plots=5):\n",
    "    fig, ax = plt.subplots(1, n_plots, figsize=(5*n_plots, 4))\n",
    "\n",
    "    for i, a in zip(images, ax):\n",
    "        a.imshow(i)\n",
    "        a.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(images=images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep a testing set to evaluate our autoencoders' ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(images, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the simplest autoencoder consisting of fully connected layers alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "encoder = Sequential()\n",
    "encoder.add(Flatten(input_shape=(120, 120, 3)))\n",
    "encoder.add(Dense(units=128, activation='relu'))\n",
    "encoder.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Decoder\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(units=128, activation='relu', input_shape=(32, )))\n",
    "decoder.add(Dense(units=120*120*3, activation='sigmoid'))\n",
    "decoder.add(Reshape(target_shape=(120, 120, 3)))\n",
    "\n",
    "autoencoder = Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are over 11 million parameters! This is a huge network. Let us compile and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(model, path, **kwargs):\n",
    "    if path.exists():\n",
    "        model.load_weights(str(path))\n",
    "    else:\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        _ = model.fit(**kwargs)\n",
    "        model.save_weights(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save(\n",
    "    model=autoencoder,\n",
    "    path=Path('./pokemon_ae_fcnn.h5'),\n",
    "    x=x_train,\n",
    "    y=x_train,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_test, x_test),\n",
    "    verbose=0,\n",
    "    epochs=200,\n",
    "    callbacks=[TqdmCallback(verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the reconstruction results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pred = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(x_test)\n",
    "plot_images(x_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that although the reconstructed images are not random, they are far from satisfactory. \n",
    "\n",
    "In fact, we can check the performance on the training set to confirm that this is not a problem of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pred = autoencoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(x_train)\n",
    "plot_images(x_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with images, it is likely that the fully connected network can capture the features much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D, Conv2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decoder, we will decrease dimensions using the pooling operation, preserving the structure of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "encoder = Sequential()\n",
    "encoder.add(\n",
    "    Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=5,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(120, 120, 3)))\n",
    "encoder.add(AveragePooling2D())\n",
    "encoder.add(\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "encoder.add(AveragePooling2D())\n",
    "encoder.add(\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "encoder.add(AveragePooling2D())\n",
    "encoder.add(\n",
    "    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(\n",
    "    Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(15, 15, 16)))\n",
    "decoder.add(UpSampling2D())\n",
    "decoder.add(\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "decoder.add(UpSampling2D())\n",
    "decoder.add(\n",
    "    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
    "decoder.add(UpSampling2D())\n",
    "decoder.add(\n",
    "    Conv2D(filters=3, kernel_size=5, padding='same', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we have much fewer parameters this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save(\n",
    "    model=autoencoder,\n",
    "    path=Path('./pokemon_ae_cnn.h5'),\n",
    "    x=x_train,\n",
    "    y=x_train,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_test, x_test),\n",
    "    verbose=0,\n",
    "    epochs=80,\n",
    "    callbacks=[TqdmCallback(verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the results of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pred = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(x_test)\n",
    "plot_images(x_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! but still not perfect.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Play with the above model to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising using U-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we do not have to do all the architectural engineering ourselves. \n",
    "\n",
    "A very oft-used CNN autoencoder-type architecture is the *U-net*, developed in [this paper](https://arxiv.org/abs/1505.04597).\n",
    "\n",
    "It is very often the case that well-known architectures have been implemented by others in keras. This is the case for U-net. We will use the following [package](https://arxiv.org/abs/1505.04597). You can install it by issuing\n",
    "```\n",
    "$pip install keras-unet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet.models import custom_unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a denoising autoencoder, by minimizing the difference between a noise-corrupted input and a clean input, i.e. we minimize\n",
    "$$\n",
    "    L(\\mathbf{x}, \\mathrm{Decoder}(\\mathrm{Encoder(\\mathbf{x + \\mathrm{Noise}})}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a simple function to add noise to the input, scaled by the `std` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(x, std=0.1):\n",
    "    x_noisy =  x + np.random.normal(scale=std, size=x.shape)\n",
    "    return np.clip(x_noisy, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = custom_unet(\n",
    "    input_shape=(120, 120, 3),\n",
    "    num_layers=3,\n",
    "    num_classes=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do on-the-fly noise generation by the `ImageDataGenerator` class. We have previously used this for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(preprocessing_function=add_gaussian_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = data_gen.flow(x=x_train, y=x_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save(\n",
    "    model=autoencoder,\n",
    "    path=Path('./pokemon_ae_denoise_unet.h5'),\n",
    "    x=generator,\n",
    "    validation_data=(x_test, x_test),\n",
    "    verbose=0,\n",
    "    epochs=80,\n",
    "    callbacks=[TqdmCallback(verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now test our model's performance on noise-corrupted test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_noisy = add_gaussian_noise(x_test, std=0.1)\n",
    "x_test_pred_noisy = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(x_test)\n",
    "plot_images(x_test_noisy)\n",
    "plot_images(x_test_pred_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Explore the performance of the model under different noise distributions, e.g.\n",
    "  * correlated Gaussian\n",
    "  * uniform\n",
    "\n",
    "How do we make the model more robust to different types of perturbations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
